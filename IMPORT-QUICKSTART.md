# Geographic Normalization Import - Quick Start

## What This Does

Imports 223,614 rows of geographic data from 8 CSV files into your database to enable location normalization and search.

## Prerequisites Checklist

- ‚úÖ Schema updated in Cursor (added columns to tiger_* tables)
- ‚úÖ CSV files exist in `data/Normalization/` (8 files)
- ‚úÖ Environment variables configured in `web/.env.local`

## Quick Start (3 Steps)

### Step 1: Install Dependencies

```bash
npm install csv-parse
```

### Step 2: Verify Schema is Ready

```bash
npx tsx scripts/verify-schema-ready.ts
```

**Expected output:**
```
‚úÖ tiger_states.state_abbreviation
‚úÖ tiger_states.population
‚úÖ tiger_states.name_fragment
... (all columns pass)

‚úÖ Schema verification PASSED
‚ú® Ready to run: npx tsx scripts/import-normalization-csvs.ts
```

If you see ‚ùå, the schema migration didn't complete. Re-run it in Cursor.

### Step 3: Run the Import

```bash
npx tsx scripts/import-normalization-csvs.ts
```

**Progress output:**
```
üöÄ Starting Geographic Normalization CSV Import
üìç Step 1: Importing States...
‚úÖ States: 60/60 rows (1234ms)
üèôÔ∏è  Step 2: Importing Metro Areas...
‚úÖ Metro Areas: 936/936 rows (2345ms)
... (continues for all 6 steps)

üìä IMPORT SUMMARY
‚úÖ States.csv: 60 rows
‚úÖ Metro Areas.csv: 936 rows
‚úÖ County to State.csv: 3,244 rows
‚úÖ ZIP to State, Town, Metro.csv: 39,494 rows
‚úÖ Zip to County.csv: 54,554 rows
‚úÖ Metro to ZIP Code.csv: 35,988 rows

Total rows inserted: 134,276
Overall duration: 118.45s
‚úÖ Import completed successfully!
```

## What Gets Imported

| Table | Rows | Data |
|-------|------|------|
| `tiger_states` | 60 | States with population |
| `tiger_cbsa` | 936 | Metro areas |
| `tiger_counties` | 3,244 | Counties |
| `tiger_zcta` | 39,494 | ZIP codes |
| `geo_zip_county` | 54,554 | ZIP‚ÜíCounty relationships |
| `geo_zip_cbsa` | 35,988 | ZIP‚ÜíMetro relationships |
| `geo_county_state` | 3,244 | County‚ÜíState relationships |

## After Import

Test the normalization:

```sql
-- Find a ZIP code's full hierarchy
SELECT
  z.geoid as zip,
  z.default_city,
  z.default_state,
  c.name as county,
  s.name as state,
  cb.name as metro
FROM tiger_zcta z
LEFT JOIN geo_zip_county zc ON z.geoid = zc.zip_geoid AND zc.is_primary
LEFT JOIN tiger_counties c ON zc.county_geoid = c.geoid
LEFT JOIN geo_county_state cs ON c.geoid = cs.county_geoid
LEFT JOIN tiger_states s ON cs.state_geoid = s.geoid
LEFT JOIN geo_zip_cbsa zcb ON z.geoid = zcb.zip_geoid AND zcb.is_primary
LEFT JOIN tiger_cbsa cb ON zcb.cbsa_geoid = cb.geoid
WHERE z.geoid = '90210';
```

## Troubleshooting

**"Cannot find module 'csv-parse'"**
```bash
npm install csv-parse
```

**"Missing Supabase credentials"**
- Check `web/.env.local` has `SUPABASE_SERVICE_KEY`

**"Column does not exist"**
- Re-run schema migration in Cursor
- Run `npx tsx scripts/verify-schema-ready.ts` to confirm

**Import fails halfway**
- Safe to re-run - uses UPSERT, won't duplicate data
- Check network connection to Supabase

## Files Created

- `scripts/import-normalization-csvs.ts` - Main import script
- `scripts/verify-schema-ready.ts` - Schema verification
- `scripts/IMPORT-NORMALIZATION-README.md` - Detailed documentation

## Next Steps

After successful import, you can:

1. **Build location search** - Autocomplete for cities, ZIPs, metros
2. **Create hierarchical navigation** - State ‚Üí County ‚Üí ZIP browsing
3. **Normalize user input** - Convert "Los Angeles" to CBSA 31080
4. **Import demographics** (optional) - `ZIP Code Demographics.csv` has 200+ fields

---

**Estimated Time:** ~2 minutes
**Total Data:** 134,276 rows across 7 tables
